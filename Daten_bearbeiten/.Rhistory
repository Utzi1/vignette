pred <- pred(Ja_in_Pro) %>%
boxplot()
length(pred)
hist(Ja_in_Pro)
hist(daten$`sort(Ja_in_Pro)`)
hist(daten$`sort(Ja_in_Pro)`, nclass = 1)
hist(daten$`sort(Ja_in_Pro)`, nclass = 8)
hist(daten$`sort(Ja_in_Pro)`, nclass = 9)
hist(Ja_in_Pro, nclass = 9)
hist(verd, nclass = 9)
library(MASS)
# generate a million lognormal samples
n <- 1000000
dat <- rlnorm(n, meanlog = 0, sdlog = 1)
# add some noise (optional)
dat <- dat + runif(n, 0, 1)
# create a vector of histogram breaks
x <- seq(0,max(dat),length=700)
# histogram the data
hst <- hist(dat, breaks=x)
# fit a lognormal distribution
fit_params <- fitdistr(dat,"lognormal")
# generate values given our fit parameters
fit <- dlnorm(x, fit_params$estimate['meanlog'], fit_params$estimate['sdlog'])
# plot the fit and original distributions
plot(x, fit, type="l", ylab="Density",
xlab="X", ylim=c(0,max(hst$density)), xlim=c(0,10))
title(main = "Density histogram with lognormal fit")
lines(hst$mid, hst$density, type="l", col="red")
legend(8,0.15,legend=c("Fit","Data"),lty=c(1,1),col=c("black","red"))
# create a vector of quantiles
quants <-seq(0,1,length=81)[2:80]
# find quantiles for the fitted distribution
fit_quants <- qlnorm(quants,fit_params$estimate['meanlog'], fit_params$estimate['sdlog'])
# find quantiles of the original data
data_quants <- quantile(dat,quants)
# fit and data quantiles side by side
data.frame(fit_quants,data_quants)
# create Q-Q plot
plot(fit_quants, data_quants, xlab="Theoretical Quantiles", ylab="Sample Quantiles")
title(main = "Q-Q plot of lognormal fit against data")
abline(0,1)
# generate a million lognormal samples
n <- 1000000
dat <- rlnorm(n, meanlog = 0, sdlog = 1)
# add some noise (optional)
dat <- dat + runif(n, 0, 1)
# create a vector of histogram breaks
x <- seq(0,max(dat),length=700)
# histogram the data
hst <- hist(dat, breaks=x)
# fit a lognormal distribution
fit_params <- fitdistr(dat,"lognormal")
# generate values given our fit parameters
fit <- dlnorm(x, fit_params$estimate['meanlog'], fit_params$estimate['sdlog'])
# plot the fit and original distributions
plot(x, fit, type="l", ylab="Density",
xlab="X", ylim=c(0,max(hst$density)), xlim=c(0,10))
title(main = "Density histogram with lognormal fit")
lines(hst$mid, hst$density, type="l", col="red")
legend(8,0.15,legend=c("Fit","Data"),lty=c(1,1),col=c("black","red"))
knitr::opts_chunk$set(echo = TRUE)
library(tidyverse)
library(MASS)
Cd_19 <- tibble(
"ConcRest" = c(.448, 1.218, 1.984, 3.56, 6.21, 9.125, 12.52, 15.12),
"qCd/Alge" = c(..2743, .503, .733, .854, .828, .765, .635, .61)
)
Cd_19 <- tibble(
"ConcRest" = c(.448, 1.218, 1.984, 3.56, 6.21, 9.125, 12.52, 15.12),
"qCd/Alge" = c(.2743, .503, .733, .854, .828, .765, .635, .61)
)
ggplot(mapping = aes(ConcRest, qCd/Alge), data=Cd_19)
ggplot(mapping = aes(Cd_19$ConcRest, `qCd/Alge`), data=Cd_19)
ggplot(mapping = aes(ConcRest, `qCd/Alge`), data=Cd_19)
ggplot(mapping = aes(ConcRest, `qCd/Alge`), data=Cd_19)+
geom_point()
ggplot(mapping = aes(ConcRest, `qCd/Alge`), data=Cd_19)+
geom_point()+
geom_histogram()
hist(Cd_19$ConcRest)
hist(Cd_19$ConcRest, nclass = 8)
hist(Cd_19$ConcRest, nclass = 9)
Cd_19 <- tibble(
"ConcRest" = c(.448, 1.218, 1.984, 3.56, 6.21, 9.125, 12.52, 15.12),
"qCd/Alge" = c(.2743, .503, .733, .854, .828, .765, .635, .61)
)
ggplot(mapping = aes(ConcRest, `qCd/Alge`), data=Cd_19)+
geom_point()
ggplot(mapping = aes(ConcRest, `qCd/Alge`), data=Cd_19)+
geom_point()+
geom_smooth()
Cd_19 <- tibble(
"ConcRest" = c(.448, 1.218, 1.984, 3.56, 6.21, 9.125, 12.52, 15.12),
"qCd/Alge" = c(.2743, .503, .733, .854, .828, .765, .635, .61),
"Absolut" = Cd_19$ConcRest * Cd_19$`qCd/Alge`
)
hist(Cd_19$Absolut)
hist(Cd_19$Absolut, nclass = 9)
df<-data.frame(x=c(1100,800,600,550,500,350),y=c(0.05,0.17,0.91,0.95,1,0.13))
opt <- optim(c(1, 1, 1), function(p) sum((dlnorm(df$x, p[1], p[2]) * p[3] - df$y)^2))
plot(x = df$x, y = df$y, type = 'b', ylim = c(0, 1), xlim = c(0, 1100))
df<-data.frame(x=c(1100,800,600,550,500,350),y=c(0.05,0.17,0.91,0.95,1,0.13))
opt <- optim(c(1, 1, 1), function(p) sum((dlnorm(df$x, p[1], p[2]) * p[3] - df$y)^2))
curve(opt$par[3] * dlnorm(x, opt$par[1], opt$par[2]), from = 0, to = 1100, add = TRUE, col = 'red'
df<-data.frame(x=c(1100,800,600,550,500,350),y=c(0.05,0.17,0.91,0.95,1,0.13))
df<-data.frame(x=c(1100,800,600,550,500,350),y=c(0.05,0.17,0.91,0.95,1,0.13))
opt <- optim(c(1, 1, 1), function(p) sum((dlnorm(df$x, p[1], p[2]) * p[3] - df$y)^2))
opt$par
plot(x = df$x, y = df$y, type = 'b', ylim = c(0, 1), xlim = c(0, 1100))
curve(opt$par[3] * dlnorm(x, opt$par[1], opt$par[2]), from = 0, to = 1100, add = TRUE, col = 'red'
plnorm(Cd_19$ConcRest)
plnorm(ConcRest, data=Cd_19)
plnorm(ConcRest)
dlnorm(Cd_19$ConcRest)
install.packages("lognorm")
library(lognorm)
library(lognorm)
lognorm::estimateParmsLognormFromSample(Cd_19$`qCd/Alge`)
params <- lognorm::estimateParmsLognormFromSample(Cd_19$`qCd/Alge`)
print(params)
dlnorm(Cd_19$ConcRest, meanlog = params[[1]], sdlog = params[[2]])
plnorm(Cd_19$ConcRest, meanlog = params[[1]], sdlog = params[[2]])
rlnorm(Cd_19$ConcRest, meanlog = params[[1]], sdlog = params[[2]])
ggplot(mapping = aes(ConcRest, `qCd/Alge`), data=Cd_19)+
geom_point()+
geom_point(mapping = aes(rlnorm(Cd_19$ConcRest, meanlog = params[[1]], sdlog = params[[2]]), `qCd/Alge`))
ggplot(mapping = aes(ConcRest, `qCd/Alge`), data=Cd_19)+
geom_point()+
geom_point(mapping = aes(rlnorm(Cd_19$ConcRest, meanlog = params[[1]], sdlog = params[[2]]) ~ `qCd/Alge`))
rlnorm(Cd_19$`qCd/Alge`, meanlog = params[[1]], sdlog = params[[2]])
rlnorm(Cd_19$`qCd/Alge`, meanlog = params[[1]], sdlog = params[[2]]) %>%
plot()
simul <- rlnorm(Cd_19$`qCd/Alge`, meanlog = params[[1]], sdlog = params[[2]])
plot(Cd_19$ConcRest, simul)
dlnorm(Cd_19$`qCd/Alge`, meanlog = params[[1]], sdlog = params[[2]])
plot(Cd_19$ConcRest,dlnorm(Cd_19$`qCd/Alge`, meanlog = params[[1]], sdlog = params[[2]]) )
plnorm(Cd_19$`qCd/Alge`, meanlog = params[[1]], sdlog = params[[2]])
plot(Cd_19$ConcRest,dlnorm(Cd_19$`qCd/Alge`, meanlog = params[[1]], sdlog = params[[2]]) )
params <- lognorm::estimateParmsLognormFromSample(Cd_19$`qCd/Alge`)
print(params)
plnorm(Cd_19$`qCd/Alge`, meanlog = params[[1]], sdlog = params[[2]])
plot(Cd_19$ConcRest,dlnorm(Cd_19$`qCd/Alge`, meanlog = params[[1]], sdlog = params[[2]]) )
fit_params <- fitdistr(Cd_19$ConcRest, "gamma", lower = c (0, 0))
fit_params
ggplot(data = dat, aes(x = Cd_19$ConcRest, y = Cd_19$`qCd/Alge`)) +
geom_point(size = 3) +
geom_line(aes(x=dat$x, y=dgamma(dat$x,fit.params$estimate["shape"], fit.params$estimate["rate"])), color="red", size = 1)
ggplot(data = dat, aes(x = Cd_19$ConcRest, y = Cd_19$`qCd/Alge`)) +
geom_point(size = 3) +
geom_line(aes(x=Cd_19$ConcRest, y=dgamma(x=Cd_19$ConcRest,fit.params$estimate["shape"], fit.params$estimate["rate"])), color="red", size = 1)
ggplot(data = dat, aes(x = Cd_19$ConcRest, y = Cd_19$`qCd/Alge`)) +
geom_point(size = 3)
ggplot()+
geom_line(aes(x=Cd_19$ConcRest, y=dgamma(x=Cd_19$ConcRest,fit.params$estimate["shape"], fit.params$estimate["rate"])), color="red", size = 1)
ggplot(data = Cd_19, aes(x = Cd_19$ConcRest, y = Cd_19$`qCd/Alge`)) +
geom_point(size = 3)
ggplot(data = Cd_19, aes(x = Cd_19$ConcRest, y = Cd_19$`qCd/Alge`)) +
geom_point(size = 3)+
geom_line(aes(x=Cd_19$ConcRest, y=dgamma(x=Cd_19$ConcRest,fit.params$estimate["shape"], fit.params$estimate["rate"])), color="red", size = 1)
params <- lognorm::estimateParmsLognormFromSample(Cd_19$`qCd/Alge`)
print(params)
plnorm(Cd_19$`qCd/Alge`, meanlog = params[[1]], sdlog = params[[2]])
plot(Cd_19$ConcRest,dlnorm(Cd_19$`qCd/Alge`, meanlog = params[[1]], sdlog = params[[2]]) )
fit_params <- fitdistr(Cd_19$ConcRest, "gamma", lower = c (0, 0))
print(fit_params)
dgamma( Cd_19$ConcRest , shape = fit.params$estimate["shape"], rate = fit.params$estimate["rate"] )
fit_params <- fitdistr(Cd_19$ConcRest, "gamma", lower = c (0, 0))
print(fit_params)
dgamma( Cd_19$ConcRest , shape = fit.params$estimate["shape"], rate = fit.params$estimate["rate"] )
dgamma( Cd_19$ConcRest , shape = fit_params$estimate["shape"], rate = fit_params$estimate["rate"] )
ggplot(data = Cd_19, aes(x = Cd_19$ConcRest, y = Cd_19$`qCd/Alge`)) +
geom_point(size = 3)+
geom_line(aes(x=Cd_19$ConcRest, y=dgamma(x=Cd_19$ConcRest,fit_params$estimate["shape"], fit_params$estimate["rate"])), color="red", size = 1)
fit_params <- fitdistr(Cd_19$ConcRest, "gamma")
print(fit_params)
ggplot(data = Cd_19, aes(x = Cd_19$ConcRest, y = Cd_19$`qCd/Alge`)) +
geom_point(size = 3)+
geom_line(aes(x=Cd_19$ConcRest, y=dgamma(x=Cd_19$ConcRest,fit_params$estimate["shape"], fit_params$estimate["rate"])), color="red", size = 1)
ggplot(data = Cd_19, aes(x = Cd_19$ConcRest, y = Cd_19$`qCd/Alge`)) +
geom_point(size = 3)+
geom_line(aes(x=Cd_19$ConcRest, y=dgamma(x=Cd_19$`qCd/Alge`,fit_params$estimate["shape"], fit_params$estimate["rate"])), color="red", size = 1)
plnorm(Cd_19$`qCd/Alge`, meanlog = params[[1]], sdlog = params[[2]])
fit_params <- fitdistr(Cd_19$ConcRest, "gamma") # fit
print(fit_params)
ggplot(data = Cd_19, aes(x = Cd_19$ConcRest, y = Cd_19$`qCd/Alge`)) +
geom_point(size = 3)+
geom_line(aes(x=Cd_19$ConcRest, y=dgamma(x=Cd_19$ConcRest,fit_params$estimate["shape"], fit_params$estimate["rate"])), color="red", size = 1)
fit_params <- fitdistr(Cd_19$ConcRest, "gamma") # fit
print(fit_params)
ggplot(data = Cd_19, aes(x = Cd_19$ConcRest, y = Cd_19$`qCd/Alge`)) +
geom_point(size = 3)+
geom_line(aes(x=Cd_19$ConcRest, y=dgamma(x=Cd_19$ConcRest,fit_params$estimate["shape"], fit_params$estimate["rate"])), color="red", size = 1)
Cd_19 <- tibble(
"ConcRest" = c(.448, 1.218, 1.984, 3.56, 6.21, 9.125, 12.52, 15.12),
"qCd/Alge" = c(.2743, .503, .733, .854, .828, .765, .635, .61)
)
A4 <- read.csv("~/Downloads/A4.csv", header=FALSE, comment.char="#")
View(A4)
A4 <- read.csv("~/Downloads/A4.csv", header=FALSE, comment.char="#")
A4 <- read.csv("~/Downloads/A4.csv", header=FALSE, comment.char="#", NA_integer_)
A4 <- read.csv("~/Downloads/A4.csv", header=FALSE, comment.char="#")
summary(A4)
plot(A4$V1, A4$V3)
library(readr)
A4 <- read_csv("Downloads/A4.csv", locale = locale(date_names = "de"),
na = "0")
View(A4)
A4 <- read_csv("Downloads/A4.csv", locale = locale(date_names = "de"),  na = "0")
plot(A4$`nm \ A`, A4$`Floureszentintensit�t`)
Lambda <- A4$`nm \ A`
library(readxl)
Dansyl_AS <- read_excel("Downloads/Dansyl-AS.xlsx",
col_types = c("numeric", "numeric", "numeric",
"numeric"))
View(Dansyl_AS)
Dansyl_AS <- read_excel("Downloads/Dansyl-AS.xlsx", col_types = c("numeric", "numeric", "numeric", "numeric"))
plot(Dansyl_AS$lambda, Dansyl_AS$Abs)
line(Dansyl_AS$lambda, Dansyl_AS$Abs)
line(Dansyl_AS$lambda, Dansyl_AS$Abs)
ggplot2::ggplot(mapping = ggplot::aes(Dansyl_AS$lambda, Dansyl_AS$Abs))+
ggplot2::geom_line()
ggplot2::ggplot(mapping = ggplot::aes(Dansyl_AS$lambda, Dansyl_AS$Abs))+
ggplot2::geom_line()
ggplot2::ggplot(mapping = ggplot2::aes(Dansyl_AS$lambda, Dansyl_AS$Abs))+
ggplot2::geom_line()
library(readxl)
HSA <- read_excel("Bachelor/Paket_BHT/Methoden_generell/HSA/HSA.xlsx",
sheet = "Tabelle2")
View(HSA)
rm()
return(1)
quit
quit()
```{r setup, include = FALSE}
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
setwd("/home/bachelor/Bachelor/Paket_BHT/BTBA1")
library(tidyverse)
library(tidyverse)
library(devtools)
library(pander)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
setwd("/home/bachelor/Bachelor/Paket_BHT/BTBA1")
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
setwd("/home/bachelor/Bachelor/Paket_BHT/BTBA1")
library(tidyverse)
library(devtools)
library(pander)
knitr::opts_chunk$set(
collapse = TRUE,
comment = "#>"
)
setwd("/home/bachelor/Bachelor/Paket_BHT/BTBA1")
```{r setup, include = FALSE}
Diese Paket soll als Langzeitalternative die Studenten im Studiengang Biotechnologie vor der Verwendung von Office-Programmen lösen.
Laden könnt ihr das Paket über:
```{r}
load_all(path = "~/Bachelor/Paket_BHT/BTBA1/")
```
# Grundlegendes
## Was macht R
Ich stelle mir R als einen mächtigen Taschenrechner vor, so mächtig, dass er wohl (fast) alles kann, warum? :
* R kann ableiten
* R kann aufleiten
* R kann mit komplexen Klassen arbeiten
* R kann Texte formatieren
* R ist beliebig erweiterbar
* eben wie ein virtueller, programmierbarer und schneller Taschenrechner!
Allerdings hängt es vom Anwender ab, wie gut all diese Möglichkeiten genutzt und angewandt werden.
Um das zu können, sollte man die Sprache R können, also mit dem Programm R interagieren.
Ein einfaches Beispiel:
```{r}
1 + 1 # das ist ein Kommentar (alles nach dem #)
1 + 2 # das sollte selbstverständlich sein
4 / 2 # auch das sollte selbstverständlich sei
2 ^ 2 # zwei im quadrat
pi    # das hier ist pi
cos( pi ) # die trigonometrische Funktion cos von pi
sin( pi ) # die trigonometrische Funktion sin von pi
e  <- exp(1) # hier wird e zur eulerschen Zahl
print( e ) # print() kann uns die Variable e printen
log( e ) # was ist der ln von e?
```
Am Beispiel von log() sehen wir, dass *log* etwas macht, diese Information was es verarbeitet ist dann in den Klammern *()* hinterlegt.
\texttt{log()} ist eine Funktion, eine Funktion um den natürlichen Logarithmus einer Zahl zu berechnen.
Funktionen wie log() sind das Rüstzeug um komplexeren Rechnungen zu trotzen, sie sind ein essentieller Teil und werden später genauer betrachtet.
Wir können beliebige Objekete erschaffen und diese Werte zuordnen um damit zu rechnen.
Beispielhaft:
```{r}
# einen Vektor
Vektor.1  <- c( 1, 2, 3, 4 ) # das c macht aus dem eingeklammerten
# eine Vektor
Vektor.2  <- c( 5, 6, 7, 8 )
Vektor.3  <- Vektor.1 * Vektor.1 # man kann viel mit Vektoren anstellen
# ein Tibble ist eine Tabelle
Vektoren <- tibble (
Vektor.1,
Vektor.2,
Vektor.3
)
# eine Liste bietet Platz für viel Information:
Liste  <- list( "Buchstaben" = c('a', 'b', 'c'),
"Zahlen" = c(1, 2, 3),
"Ein Satz" = "Ick kann janich so viel fressen, wie ick kotzen möchte!
, Max Liebermann")
# Wenn wir nur den Namen eines Objekt schreiben
# bekommen wir das Objekt ausgegeben
Vektor.1
Vektor.2
Vektor.3
Vektoren
Liste
Vektor.3  <- Vektor.1 * Vektor.1 # man kann viel mit Vektoren anstellen
# ein Tibble ist eine Tabelle
Vektoren <- tibble (
Vektor.1,
Vektor.2,
Vektor.3
)
# eine Liste bietet Platz für viel Information:
Liste  <- list( "Buchstaben" = c('a', 'b', 'c'),
"Zahlen" = c(1, 2, 3),
"Ein Satz" = "Ick kann janich so viel fressen, wie ick kotzen möchte!
, Max Liebermann")
# Wenn wir nur den Namen eines Objekt schreiben
# bekommen wir das Objekt ausgegeben
Vektor.1
Vektor.2
Vektor.3
Vektoren
Liste
Eine besondere Wichtigkeit bekommt das Pfeilchen zugesprochen, es ist innerhalb der Sprache R in der Lage einen Wert zuzuordnen
Diese Zuordnung beschränkt nicht nur auf einfache Werte sondern gilt auch für Funktionen, Vektoren, Listen und so weiter.
Vektoren, Listen, Tibbles usw. werden als Klasse bezeichnet, durch Zuordnung von Werten werden aus den Klassen Objekten.
Man kann sich eine Klasse also ein wenig wie das Fließschema eines Bioreaktor vorstellen, wenn das Fließschema aus Metall gebaut wird und nicht mehr nur theoretisch existiert wird es zum Objekt, "mit Leben gefüllt", so wie wenn eben einer Klasse Werte zugeordnet werden.
Der Vektor entsteht also durch Zuordnung von Daten zu einer leeren Klasse und bekommt dann einen Namen und einen klaren Sinn.
Bei der Benennung eines Objektes sollte man sich Gedanken machen, nicht alle Namen sind sinnvoll, ein Leerzeichen kann da schon zu viel Problemen führen.
Möchte man ein Objekt benennen sollte man vermeiden:
* *-* ist eben ein Minus-Operator
* *+* ist der Plus-Operator
* _*_ ist der Mal-Operator
* */* ist ist zum teilen
* *?* beschafft Hilfe :-), probier aus!
* *:* ein Sequenz-Operator
* *= , <, >, & * weitere Operatoren, später mehr!
Punkte und Unterstriche sind innerhalb der R-Umgebung ideal um Namen von Objekten zu strukturieren, Beispiele gab's bereits.
Mehr dazu findet man zum Beispiel in @R_gen oder @RFDS.
Um Vektoren durch bekannte mathematische Operationen zu generieren stehen uns verschiedene Funktionen zur Verfügung:
```{r}
# von eins bis 10 zählen:
x  <- 1:10 %>% # eine Pipe, eine 'Röhre' zwischen den Funktinen
print()
# Von 1 bis 10 in 0.5-er Schritten:
x  <- seq(1, 10, 0.5) %>%
print()
# einen Vektor der Länge 5 generieren:
x <- seq(1, 10, len = 5) %>%
print()
```
seq() eignet sich gut für Sequenzen, rep() ist der Counterpart und wiederholt.
Es ist auch möglich mit Buchstaben zu arbeiten, die heißen dann "character" aber interessieren uns erst mal nicht.
Wichtig zu beachten ist, ist dass es einen Unterschied macht, wenn wir einen Buchstaben ohne Anführungszeichen verwenden oder mit!
```{r}
print("Albatross")
Albatross <- 'Legehenne'
print(Albatross)
Satz <- "Die Legehenne kennt's Eierlegen gut, sie macht's die ganze Zeit"
print(Satz)
Satz <- "Die Legehenne kennt's Eierlegen gut, sie macht's die ganze Zeit"
print(Satz)
Satz <- "Die Legehenne kennt's Eierlegen gut, sie macht's die ganze Zeit"
print(Satz)
## Datenimport
Der Datenimport stellt häufig eine Hürde dar, die Messdaten liegen ja teilweise gar nicht als tibble oder Vektor oder Liste in der R-Umgebung rum sondern häufig als Excel-Tabelle im Ordner Downloads oder auf dem Desktop, weit weg von unserer R-Umgebung, die R-Umgebung ist übrigens der virtuelle Taschenrechner.
Um nun Messdaten für uns nutzbar zu machen, müssen wir sie importieren wobei es nun wichtig ist zu wissen:
* wo die Daten sind
* in welchem Format sie vorliegen
* Was wir mit ihnen machen wollen
Der letze Punkt bezieht sich auf den Arbeitsaufwand.
Beispielhaft hat man vier bereits vorbearbeitete Messwerte, diese können auch skrupellos abgetippt oder kopiert werden.
Sollte es sich lohnen die Daten zu importieren stellt sich die Frage was eigentlich importiert wird, zum Beispiel eine Exceldatei oder eine CSV-Datei (comma separated value).
Das Dateiformat ist Maßgeblich relevant bei der Wahl einer Funktion zum Import.
Das "Wo" bezieht sich auf einen Dateipfad.
Dieser gibt uns an wo auf unserem System die Datei auffindbar ist.
Eine solche Datei muss aber nicht zwingend auf unserem Computer sein, sie kann sich auch im www befinden oder auf einem USB-Stick.
Hier ist die Verwendung von R Studio sehr bequem, es ermöglicht uns innerhalb unseres Computers Dateien zu Suchen und generiert dann einen Code um den Datensatz zu importieren.
Ein solcher Code besteht immer aus einer Import-Funktion, dem Dateipfad und optionalen Informationen:
```{r}
# Laden der benötigten Funktion
library(readxl)
# Anwenden der Funktion
Rohdaten <- read_excel("~/Bachelor/Paket_BHT/Methoden_generell/aerober_abbau_detergenzien.xlsx")
print(Rohdaten)
```
Der Importierte Datensatz heißt aerober_abbau_detergenzien.xlsx und wurde über readxl() importiert, in der R Umgebung heißt er nun Rohdaten.
Der Dateipfad ist in Anführungszeichen.
Nun liegt der Datensatz als "Rohdaten" vor und man kann damit arbeiten.
> es ist empfehlenswert die Messwerterfassung so einfach wie möglich durchzuführen, komplexe Tabellenstrukturen schaden da dem Datenimport und sind auch fürs Verständnis nicht unbedingt hilfreich.
Wenn beim Datenimport Probleme entstehen wird ein kleiner Text auf der Konsole erscheinen, dieser meistens sehr hilfreich um das Problem zu lösen, bei Härtefällen sollte eine Internetrecherche aber auch gute Lösungsansätze bringen.
## Einfache Operationen
Die eben geladenen Messdaten sind nun innerhalb der R Umgebung für uns zugänglich, wir können sie nun untersuchen.
Im Beispieldatensatz wurde die $O_2$-Konzentration in Wasser vor und nach der Behandlung mit Mikroorganismen gemessen.
Das Wasser selbst wurde mit organischen Verschmutzungen belastet welche im Laufe der Zeit von Mikroorganismen abgebaut wurden.
Während des Abbaus wurde Sauerstoff verbraucht.
Die $O_2$-Anfangskonzentration sollte bei allen Gruppen gleich sein, wir können ja mal den Mittelwert berechnen:
```{r}
# das Arithmetische Mittel:
mean(Rohdaten$`O2 [mg/L] davor`)
# und einen Boxplot:
boxplot(Rohdaten$`O2 [mg/L] davor`)
```
Bei genauerer Betrachtung fällt beim Boxplot ein Kreis auf Höhe der Null auf, es handelt sich um einen Datenpunkt welcher doch merkwürdig scheint.
Wir möchten diesen Wert genauer untersuchen, dazu können wir ein Zusammenfassung erstellen:
```{r}
summary(Rohdaten$`O2 [mg/L] davor`)
```
Wir sehen, dass das Minimum Null beträgt, eine recht unwahrscheinliches Ergebnis da im Versuch für alle sechs Durchläufe immer das Selbe Wasser aus dem selben Ansatz verwendet wurde.
Da keine Information zum Messwert vorliegt, welche explizit auf einen Messfehler verweist, sollten nun Überlegungen angestellt werden, ob es legitim ist den Wert als Ausreißer zu verwerfen.
Es gibt eine umfassendes Paket \texttt{outliers}:
```{r}
library(outliers) # laden des Paketes
dixon.test(Rohdaten$`O2 [mg/L] davor`)
grubbs.test(Rohdaten$`O2 [mg/L] davor`)
chisq.out.test(Rohdaten$`O2 [mg/L] davor`)
rm.outlier(Rohdaten$`O2 [mg/L] davor`) %>%
boxplot()
Die Ausreißer-Tests geben immer eine kleine Zusammenfassung und eine Begründung zu ihrer Wahl, das erleichtert den Umgang mit ihnen.
Abhängig von der Fragestellung wird empfohlen sich mit der Arbeitsweise der Tests auseinander zu setzen, dann kann auch besser beurteilt werden, ob das gewählte Vorgehen zulässig ist.
## Datentransformation
Zu Beginn kann es oft schwer sein sich innerhalb von Datensätzen zurecht zu finden und jene Werte, welche von Interesse scheinen zugänglich zu machen.
Im obigen Beispiel hatten wir es leicht, es gab nur einen Ausreißer welcher sich leicht entfernen lies.
Um mit dem Datensatz nun weiter arbeiten zu können, möchten wir den Ausreißer aber ganz entfernen.
Das Paket \texttt{dplyr} bietet dazu die passenden Funktionen.
```{r}
# Filtern der sinvollen Werte
library(dplyr) # laden des benötigten Paket
Daten <- filter(Rohdaten
, Rohdaten$"O2 [mg/L] davor" > 1) %>%
print()
```
Progesteron.Standard <- read_excel("Progesteron.xlsx", sheet = 2)
library(pander)
library(magrittr)
library(tidyverse)
tibble(
"Messung 1" = c("Wert 1", "Wert 2", "Wert 3", "Wert 4"),
"Messung 2" = c("Wert 1", "Wert 2", "Wert 3", "Wert 4"),
"Messung n" = c("Wert 1", "Wert 2", "Wert 3", "Wert 4")
) %>%
pander()
Messdaten <- tibble(
"Messung 1" = c("Wert 1", "Wert 2", "Wert 3", "Wert 4"),
"Messung 2" = c("Wert 1", "Wert 2", "Wert 3", "Wert 4"),
"Messung n" = c("Wert 1", "Wert 2", "Wert 3", "Wert 4")
)
Datensatz <- list(
temp.  <- c("Temperatur 1", "Temperatur 2", "Temperatur 3", "Temperatur 4"),
Messdaten,
"Viskosität"  <- c("Viskosität 1", "Viskosität 2", "Viskosität 3", "Viskosität 4")
)
pander(Datensatz)
library(readxl)
Progesteron.Standard <- read_excel("Progesteron.xlsx", sheet = 2)
Progesteron.Proben.1 <- read_excel("Progesteron.xlsx", sheet = 3)
Progesteron.Proben.2 <- read_excel("Progesteron.xlsx", sheet = 4)
Messwerte <- list(Progesteron.Standard <- read_excel("Progesteron.xlsx", sheet = 2)
Progesteron.Proben.1 <- read_excel("Progesteron.xlsx", sheet = 3)
Messwerte <- list(
Progesteron.Standard <- read_excel("Progesteron.xlsx", sheet = 2),
Progesteron.Proben.1 <- read_excel("Progesteron.xlsx", sheet = 3),
Progesteron.Proben.2 <- read_excel("Progesteron.xlsx", sheet = 4)
)
pander(Messwerte)
install.packages("OutlierDetection")
install.packages("depth")
install.packages("rgl")
library(DDoutlier)
source('~/Bachelor/Paket_BHT/Vignette/Daten_bearbeiten/Daten_bearbeiten.R', echo=TRUE)
setwd("Bachelor/Paket_BHT/Vignette/Daten_bearbeiten/")
library(pander)
library(magrittr)
library(tidyverse)
library(readxl)
# Die orginale Tabelle direkt in R importiert:
read_excel("ProgesteronVK.xlsx")
# aus der vonangegangenen Tabelle wurde nach Umformung in
# Ecxel diese Liste generiert
Messwerte <- list(
"Diese Liste enthält die Messwerte der ursprünglichen Tabelle, nur sauberer für R",
Progesteron.Standard <- read_excel("Progesteron.xlsx", sheet = 2),
Progesteron.Proben.1 <- read_excel("Progesteron.xlsx", sheet = 3),
Progesteron.Proben.2 <- read_excel("Progesteron.xlsx", sheet = 4)
)
library(outliers)
library(DDoutlier)
# Distance-based outlier detection based on user-given neighborhood size
DB(dataset = Messwerte[[2]] , d = 1)
# Distance-based outlier detection based on user-given neighborhood size
DB(dataset = Messwerte[[2]]$`0` , d = 1)
# Installation eines weiteren Paketes
library(devtools)
install_github("https://github.com/cran/OutlierDetection.git")
rversions::r_versions()
